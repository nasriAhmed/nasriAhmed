# Ahmed Nasri | DÃ©veloppeur Full-Stack Python ğŸ

ğŸ¯ **Ã€ propos de moi**  
DÃ©veloppeur Full-Stack Python avec plus de 8 ans d'expÃ©rience, spÃ©cialisÃ© dans :
- **DÃ©veloppement d'APIs REST** : (Flask, FastAPI, Django) sÃ©curisÃ©es et performantes.
- **Big Data et Analyse** : Traitement et manipulation de donnÃ©es massives avec des outils comme PySpark et Pandas.
- **DevOps et CI/CD** : IntÃ©gration et dÃ©ploiement continu avec Docker, Kubernetes, GitLab CI/CD.
- **ModÃ©lisation Machine Learning** : DÃ©veloppement et dÃ©ploiement de modÃ¨les pour la prÃ©diction et l'analyse.
- **Mise en place d'architectures** robustes et scalables pour des applications web et Big Data
- **Cloud & Azure :** MaÃ®trise des services **Azure Key Vault**, **Azure Databricks**, **Azure Storage**.
- **Scrum Master certifiÃ© :** Gestion Agile et optimisation des processus de dÃ©veloppement

ğŸ“„ **[Mon CV](./CV_Ahmed_Nasri_Developpeur_Full_Stack_Python_Senior.pdf)**  
ğŸ“§ **Email** : ahmed.nasri.ing@gmail.com  
ğŸŒ **LinkedIn** : [Ahmed Nasri](https://www.linkedin.com/in/ahmed-nasri-507abb66)
---

## ğŸš€ Projets Techniques

### **1. [SystÃ¨me de Gestion de BibliothÃ¨que avec Flask & MongoDB](https://github.com/nasriAhmed/library_management)**
- **Objectif** : Ce projet est une API RESTful permettant de gÃ©rer une bibliothÃ¨que avec :
  - ğŸ“– **Gestion des auteurs :** Ajouter, lister et supprimer des auteurs.
  - ğŸ“š **Gestion des livres :** Ajouter, lister et supprimer des livres.
  - ğŸ”„ **Gestion des emprunts :** Permet aux utilisateurs d'emprunter des livres et de gÃ©rer le stock en temps rÃ©el.
  - ğŸ” **Authentification JWT :** SÃ©curisation des accÃ¨s avec JSON Web Token.
  - ğŸ” **Recherche de livres :** Endpoint permettant de retrouver un livre par son titre.
  - ğŸ— **DÃ©ploiement avec Docker & MongoDB :** Conteneurisation pour une exÃ©cution facile et rapide.
  - ğŸ“Š **Gestion des logs :** Supervision avancÃ©e des performances avec des logs et un suivi des requÃªtes.
- ğŸ— **DÃ©ploiement avec Docker & MongoDB**..
- **DÃ©tails Techniques** :
   - **Python** (Flask, MongoEngine, PyJWT, Pandas)
   - **Base de donnÃ©es :** MongoDB.
   - **Gestion des Logs :** logging pour suivre les opÃ©rations de l'API.
   - **Tests Unitaires :** Pytest pour la validation des endpoints.
   - **Conteneurisation & DÃ©ploiement :** Docker, Docker Compose.
- **Challenges RÃ©solus** :
    - ğŸ“Œ Stockage optimisÃ© avec MongoDB pour gÃ©rer efficacement les relations entre les livres, auteurs et emprunts.
    - ğŸ” SÃ©curisation des accÃ¨s avec JWT pour protÃ©ger les endpoints sensibles.
    - ğŸ“Š Monitoring des performances via des logs structurÃ©s.
    - ğŸ› ï¸ Automatisation des tests avec Pytest pour garantir la fiabilitÃ© des endpoints API.
    -  ğŸ— DÃ©ploiement facile avec Docker, permettant une mise en production rapide et reproductible
- **Tech Stack** :
    -  **Langage :** Python
    -  **Framework Web :** Flask (Flask-RESTful, Flask-JWT-Extended)
    -  **Base de donnÃ©es :** MongoDB avec MongoEngine
    -  **Outils de Conteneurisation :** Docker, Docker Compose
    -  **Gestion des logs et monitoring :** Logging Python
    -  **Tests :** Pytest pour les tests unitaires

---

### **2. [ETL avec Airflow et Pandas](https://github.com/nasriAhmed/Etl_airflow_pandas)**
- **Objectif** : Mise en place d'un pipeline ETL pour extraire, transformer et charger des donnÃ©es brutes vers une base de donnÃ©es optimisÃ©e.
- **DÃ©tails Techniques** :
  - **Airflow** : Orchestration et planification des tÃ¢ches.
  - **Pandas** : Nettoyage et transformation des donnÃ©es.
  - **Monitoring** : Prometheus pour la collecte des mÃ©triques, Grafana pour la visualisation.
  - **Docker** : Conteneurisation du pipeline.
- **Challenges RÃ©solus** :
  - Supervision avancÃ©e des performances grÃ¢ce Ã  des tableaux de bord en temps rÃ©el.
  - Gestion des tÃ¢ches longues avec rÃ©cupÃ©ration automatique en cas dâ€™Ã©chec.
- **Tech Stack** : Python, Apache Airflow, Pandas, Prometheus, Grafana, Docker.

---

### **3. [Analyse des Logs avec PySpark](https://github.com/nasriAhmed/Analyse_des_logs_avec_PySpark)**
- **Objectif** : Analyser des fichiers de logs volumineux pour dÃ©tecter des anomalies et des tendances.
- **DÃ©tails Techniques** :
  - **PySpark** : Traitement distribuÃ© des donnÃ©es pour gÃ©rer des volumes massifs.
  - **Visualisation** : Utilisation de Matplotlib pour reprÃ©senter les rÃ©sultats.
- **Features** :
  - Filtrage et agrÃ©gation des donnÃ©es pour obtenir des insights utiles.
  - Exportation des rÃ©sultats sous forme de rapports prÃªts Ã  l'emploi.
- **Tech Stack** : Python, PySpark, Matplotlib.

---

### **4. [Drone Visit Sites](https://github.com/nasriAhmed/Drone_Visit_sites)**
- **Objectif** : DÃ©veloppement dâ€™une application pour planifier et optimiser les visites de drones sur des sites spÃ©cifiques.
- **DÃ©tails Techniques** :
  - **Backend** :
    - API REST en **Python Flask**.
  - **Base de DonnÃ©es** :
    - **PostgreSQL/PostGIS** pour les calculs gÃ©ospatiaux avancÃ©s.
  - **DevOps** :
    - Dockerisation complÃ¨te.
    - CI/CD avec GitLab.
  - **Tests** :
    - Tests backend avec **Pytest**.
- **Tech Stack** : Python Flask, sqlalchemy, PostgreSQL, Docker, Pytest.

---

### **5. [Simulation Ã‰pidÃ©miologique avec des Multi-Agents](https://github.com/nasriAhmed/Project_Covid_19)**
- **Objectif** : ModÃ©lisation de la propagation d'Ã©pidÃ©mies avec des agents intelligents et du deep learning.
- **DÃ©tails Techniques** :
  - **Deep Learning** : Utilisation de RNN (Recurrent Neural Networks) pour la prÃ©diction.
  - **Simulation Multi-Agents** : ModÃ©lisation des interactions entre agents (populations, lieux).
  - **Graph Neural Networks** : Analyse des relations spatio-temporelles des donnÃ©es.
- **Tech Stack** : Python, TensorFlow, Matplotlib, Quantum.

----------

## ğŸ› ï¸ CompÃ©tences Techniques

| **CatÃ©gorie**              | **CompÃ©tences**                                                                 |
|----------------------------|---------------------------------------------------------------------------------|
| **Langages de Programmation** | Python, JavaScript, PHP, SQL                                                 |
| **Frameworks**              | Flask, Django, Pandas, PySpark, TensorFlow, Keras                             |
| **Bases de DonnÃ©es**        | PostgreSQL, MySQL, MongoDB, SQLite                                            |
| **DevOps**                  | Docker, GitLab CI/CD, Prometheus, Grafana, Kubernetes                         |
| **Cloud**                   | Microsoft Azure (Blob Storage, Databricks)                          |
| **MÃ©thodologies**           | Agile (Scrum), TDD, BDD                                                      |
| **Tests**                   | Pytest, Unittest, Coverage                                                   |

---

## ğŸ“Š Statistiques GitHub

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=ahmednasri&show_icons=true&theme=radical)  
![Top Langages](https://github-readme-stats.vercel.app/api/top-langs/?username=ahmednasri&layout=compact&theme=radical)

---

## ğŸ”§ Projets en Cours

- **Application CRUD avec Django et Docker** : CrÃ©ation d'une API sÃ©curisÃ©e pour la gestion des utilisateurs.
- **Automatisation avec Apache Airflow** : DÃ©veloppement dâ€™un pipeline ETL complexe intÃ©grant des sources de donnÃ©es multiples.
- **Analyse FinanciÃ¨re avec Polars** : Utilisation de Polars pour traiter et analyser rapidement des datasets financiers.

---

## ğŸŒŸ Points Forts

1. Expertise en Python et frameworks associÃ©s.
2. MaÃ®trise des environnements cloud et DevOps.
3. Passion pour les systÃ¨mes distribuÃ©s et l'optimisation des pipelines de donnÃ©es.
4. CapacitÃ© Ã  livrer des solutions robustes et scalables adaptÃ©es aux besoins clients.

---

## ğŸ›¡ï¸ Badges

- ![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
- ![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)
- ![Django](https://img.shields.io/badge/Django-4.0%2B-darkgreen)
- ![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue)


ğŸŒ **N'hÃ©sitez pas Ã  explorer mes dÃ©pÃ´ts et Ã  me contacter pour toute collaboration ou opportunitÃ© !**
